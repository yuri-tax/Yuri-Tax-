{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing, cross_validation, neighbors, manifold\n",
    "from sklearn import cross_validation, metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Col1</th>\n",
       "      <th>Col2</th>\n",
       "      <th>Col3</th>\n",
       "      <th>Col4</th>\n",
       "      <th>Col5</th>\n",
       "      <th>Col6</th>\n",
       "      <th>Col7</th>\n",
       "      <th>Col8</th>\n",
       "      <th>Col9</th>\n",
       "      <th>Col10</th>\n",
       "      <th>Col11</th>\n",
       "      <th>Col12</th>\n",
       "      <th>Class_att</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.027818</td>\n",
       "      <td>22.552586</td>\n",
       "      <td>39.609117</td>\n",
       "      <td>40.475232</td>\n",
       "      <td>98.672917</td>\n",
       "      <td>-0.254400</td>\n",
       "      <td>0.744503</td>\n",
       "      <td>12.5661</td>\n",
       "      <td>14.5386</td>\n",
       "      <td>15.30468</td>\n",
       "      <td>-28.658501</td>\n",
       "      <td>43.5123</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.056951</td>\n",
       "      <td>10.060991</td>\n",
       "      <td>25.015378</td>\n",
       "      <td>28.995960</td>\n",
       "      <td>114.405425</td>\n",
       "      <td>4.564259</td>\n",
       "      <td>0.415186</td>\n",
       "      <td>12.8874</td>\n",
       "      <td>17.5323</td>\n",
       "      <td>16.78486</td>\n",
       "      <td>-25.530607</td>\n",
       "      <td>16.1102</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68.832021</td>\n",
       "      <td>22.218482</td>\n",
       "      <td>50.092194</td>\n",
       "      <td>46.613539</td>\n",
       "      <td>105.985135</td>\n",
       "      <td>-3.530317</td>\n",
       "      <td>0.474889</td>\n",
       "      <td>26.8343</td>\n",
       "      <td>17.4861</td>\n",
       "      <td>16.65897</td>\n",
       "      <td>-29.031888</td>\n",
       "      <td>19.2221</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>Prediction is done by using binary classificat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69.297008</td>\n",
       "      <td>24.652878</td>\n",
       "      <td>44.311238</td>\n",
       "      <td>44.644130</td>\n",
       "      <td>101.868495</td>\n",
       "      <td>11.211523</td>\n",
       "      <td>0.369345</td>\n",
       "      <td>23.5603</td>\n",
       "      <td>12.7074</td>\n",
       "      <td>11.42447</td>\n",
       "      <td>-30.470246</td>\n",
       "      <td>18.8329</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49.712859</td>\n",
       "      <td>9.652075</td>\n",
       "      <td>28.317406</td>\n",
       "      <td>40.060784</td>\n",
       "      <td>108.168725</td>\n",
       "      <td>7.918501</td>\n",
       "      <td>0.543360</td>\n",
       "      <td>35.4940</td>\n",
       "      <td>15.9546</td>\n",
       "      <td>8.87237</td>\n",
       "      <td>-16.378376</td>\n",
       "      <td>24.9171</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Col1       Col2       Col3       Col4        Col5       Col6  \\\n",
       "0  63.027818  22.552586  39.609117  40.475232   98.672917  -0.254400   \n",
       "1  39.056951  10.060991  25.015378  28.995960  114.405425   4.564259   \n",
       "2  68.832021  22.218482  50.092194  46.613539  105.985135  -3.530317   \n",
       "3  69.297008  24.652878  44.311238  44.644130  101.868495  11.211523   \n",
       "4  49.712859   9.652075  28.317406  40.060784  108.168725   7.918501   \n",
       "\n",
       "       Col7     Col8     Col9     Col10      Col11    Col12 Class_att  \\\n",
       "0  0.744503  12.5661  14.5386  15.30468 -28.658501  43.5123  Abnormal   \n",
       "1  0.415186  12.8874  17.5323  16.78486 -25.530607  16.1102  Abnormal   \n",
       "2  0.474889  26.8343  17.4861  16.65897 -29.031888  19.2221  Abnormal   \n",
       "3  0.369345  23.5603  12.7074  11.42447 -30.470246  18.8329  Abnormal   \n",
       "4  0.543360  35.4940  15.9546   8.87237 -16.378376  24.9171  Abnormal   \n",
       "\n",
       "                                         Unnamed: 13  \n",
       "0                                                NaN  \n",
       "1                                                NaN  \n",
       "2  Prediction is done by using binary classificat...  \n",
       "3                                                NaN  \n",
       "4                                                NaN  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing data\n",
    "data_set = pd.read_csv(\"~/Desktop/Dataset_spine.csv\",header = 0)\n",
    "data_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data stored per column, x is all the data mines the last column: y, since y contains the classification of the data\n",
    "data_set['Class_Ord'] = pd.Categorical(data_set.Class_att).codes \n",
    "\n",
    "X_Y = data_set[[\n",
    "'Col1',\n",
    "'Col2',\n",
    "'Col3',\n",
    "'Col4',\n",
    "'Col5',\n",
    "'Col6',\n",
    "'Col7',\n",
    "'Col8',\n",
    "'Col9',\n",
    "'Col10',\n",
    "'Col11',\n",
    "'Col12',\n",
    "'Class_Ord'\n",
    "]] \n",
    "\n",
    "#X = preprocessing.normalize(np.array(X_Y.drop(['Class_Ord'], 1)),norm='l1')\n",
    "X = np.array(X_Y.drop(['Class_Ord'], 1))\n",
    "\n",
    "X_best_features = np.array(X_Y.drop(['Class_Ord','Col7',\n",
    "'Col8',\n",
    "'Col9',\n",
    "'Col10',\n",
    "'Col11',\n",
    "'Col12',\n",
    "'Col4',\n",
    "],1))\n",
    "\n",
    "Y = np.array(data_set['Class_Ord'])\n",
    "\n",
    "X_no_outlier = np.delete(X_best_features,(115),axis=0)\n",
    "Y_no_outlier = np.delete(Y,(115),axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_prediction: 0.837419354839\n",
      "f1-score: 0.782608695652\n",
      "confusion matrix:\n",
      "[[34  8]\n",
      " [ 2 18]]\n"
     ]
    }
   ],
   "source": [
    "#To use the different data input; best_features, no_oulier, change the X in test_split.\n",
    "#When using no_oulier, also Y has to be Y_no_outlier due to the change in input size.\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, Y, test_size = 0.2)\n",
    "\n",
    "\n",
    "mlp = nn(hidden_layer_sizes=(12,12),\n",
    "                    activation='logistic', solver='adam',\n",
    "                    alpha=0.0001, batch_size='auto',\n",
    "                    learning_rate='constant',\n",
    "                    learning_rate_init=0.001,\n",
    "                    power_t=0.5, max_iter=10000,\n",
    "                    shuffle=True,\n",
    "                    random_state=None,\n",
    "                    tol=0.0001,\n",
    "                    verbose=False,\n",
    "                    warm_start=False,\n",
    "                    momentum=0.9,\n",
    "                    nesterovs_momentum=True,\n",
    "                    early_stopping=False,\n",
    "                    validation_fraction=0.1,\n",
    "                    beta_1=0.9,\n",
    "                    beta_2=0.999,\n",
    "                    epsilon=1e-08)\n",
    "\n",
    "\n",
    "n=1\n",
    "amount_of_iterations = 50\n",
    "predict_accuracy_list = []\n",
    "predict_class1 = []\n",
    "\n",
    "while n<=amount_of_iterations:\n",
    "    mlp.fit(X_train, y_train)\n",
    "    predict_accuracy = mlp.score(X_test, y_test)\n",
    "    predict_accuracy_list = np.append(predict_accuracy_list, predict_accuracy)\n",
    "    predict_class1 = mlp.predict(X_test)\n",
    "    n = n+1\n",
    "    \n",
    "print \"average_prediction:\",np.average(predict_accuracy_list)\n",
    "\n",
    "predict_class = mlp.predict(X_test)\n",
    "\n",
    "f1 = metrics.f1_score(y_test, predict_class)\n",
    "print \"f1-score:\",f1\n",
    "\n",
    "\n",
    "#Confusion matrix\n",
    "cf_matrix = metrics.confusion_matrix(y_test, predict_class1)\n",
    "print \"confusion matrix:\"\n",
    "print cf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#running this will give a graph in an external window, this needs to be closed again before anything else can be run!!\n",
    "######################################################################################################################\n",
    "\n",
    "#performing manifold on the data\n",
    "mds = manifold.MDS()\n",
    "co = mds.fit(X_no_outlier, y=Y_no_outlier, init=None)\n",
    "co_t = mds.fit_transform(X, y=Y)\n",
    "maxindex = co_t.argmax()\n",
    "matrix_co_t = np.matrix(co_t)\n",
    "plt.plot(matrix_co_t[:,0], matrix_co_t[:,1], 'x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
